{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO5Rg1PnQR9GWFp6cvv4qwK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ine0ftk1wMZA",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/Data/Ankidroid_bow_features.csv', dtype={'is_vulnerable': bool})\n",
        "data['is_vulnerable'] = data['is_vulnerable'].map({False: 0, True: 1})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UKMSBJFv9t7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = data.loc[:, data.columns != 'is_vulnerable']\n",
        "y = data['is_vulnerable']\n",
        "SEQUENCE_LENGTH = x.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7aIqz5EWvlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "TEST_SPLIT = 0.2\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=TEST_SPLIT, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uexvjI5Sw3gO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzgcV6RCF1o8",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpdwj4VCd5Vl",
        "colab_type": "code",
        "outputId": "841a4748-8f46-41db-a3eb-db2fb4a2f3fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Random forest\n",
        "random_forest_classifier = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
        "random_forest_classifier.fit(x_train, y_train)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PU6rnmSd5N5",
        "colab_type": "code",
        "outputId": "329a8e7d-d4ad-4c94-c20f-ca821d575318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "print(\"TRAIN\")\n",
        "\n",
        "predicted_rf = random_forest_classifier.predict(x_train)\n",
        "predicted_prob_rf = random_forest_classifier.predict_proba(x_train)\n",
        "\n",
        "confusion = sklearn.metrics.confusion_matrix(y_true=y_train, y_pred=predicted_rf)\n",
        "print(confusion)\n",
        "tn, fp, fn, tp = confusion.ravel()\n",
        "print('\\nTP:',tp)\n",
        "print('FP:',fp)\n",
        "print('TN:',tn)\n",
        "print('FN:',fn)\n",
        "\n",
        "## Performance measure\n",
        "print('\\nAccuracy: '+ str(sklearn.metrics.accuracy_score(y_true=y_train, y_pred=predicted_rf)))\n",
        "print('Precision: '+ str(sklearn.metrics.precision_score(y_true=y_train, y_pred=predicted_rf)))\n",
        "print('Recall: '+ str(sklearn.metrics.recall_score(y_true=y_train, y_pred=predicted_rf)))\n",
        "print('F-measure: '+ str(sklearn.metrics.f1_score(y_true=y_train, y_pred=predicted_rf)))\n",
        "print(\"False Positive Rate:\" + str(fp/(tn+fp)))\n",
        "print('AUC: '+ str(sklearn.metrics.roc_auc_score(y_true=y_train, y_score=np.argmax(predicted_prob_rf,axis = 1))))\n",
        "print('Precision-Recall AUC: '+ str(sklearn.metrics.average_precision_score(y_true=y_train, y_score=np.argmax(predicted_prob_rf,axis = 1))))\n",
        "print('MCC: '+ str(sklearn.metrics.matthews_corrcoef(y_true=y_train, y_pred=predicted_rf)))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN\n",
            "[[ 86   1]\n",
            " [  1 135]]\n",
            "\n",
            "TP: 135\n",
            "FP: 1\n",
            "TN: 86\n",
            "FN: 1\n",
            "\n",
            "Accuracy: 0.9910313901345291\n",
            "Precision: 0.9926470588235294\n",
            "Recall: 0.9926470588235294\n",
            "F-measure: 0.9926470588235294\n",
            "False Positive Rate:0.011494252873563218\n",
            "AUC: 0.9905764029749831\n",
            "Precision-Recall AUC: 0.9898324883237389\n",
            "MCC: 0.9811528059499662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GMe-FMPpDsR",
        "colab_type": "code",
        "outputId": "c2688b88-91dd-46f5-f422-4afa0bca3fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "print(\"TEST\")\n",
        "\n",
        "\n",
        "predicted_rf = random_forest_classifier.predict(x_test)\n",
        "predicted_prob_rf = random_forest_classifier.predict_proba(x_test)\n",
        "\n",
        "confusion = sklearn.metrics.confusion_matrix(y_true=y_test, y_pred=predicted_rf)\n",
        "print(confusion)\n",
        "tn, fp, fn, tp = confusion.ravel()\n",
        "print('\\nTP:',tp)\n",
        "print('FP:',fp)\n",
        "print('TN:',tn)\n",
        "print('FN:',fn)\n",
        "\n",
        "## Performance measure\n",
        "print('\\nAccuracy: '+ str(sklearn.metrics.accuracy_score(y_true=y_test, y_pred=predicted_rf)))\n",
        "print('Precision: '+ str(sklearn.metrics.precision_score(y_true=y_test, y_pred=predicted_rf)))\n",
        "print('Recall: '+ str(sklearn.metrics.recall_score(y_true=y_test, y_pred=predicted_rf)))\n",
        "print('F-measure: '+ str(sklearn.metrics.f1_score(y_true=y_test, y_pred=predicted_rf)))\n",
        "print(\"False Positive Rate:\" + str(fp/(tn+fp)))\n",
        "print('AUC: '+ str(sklearn.metrics.roc_auc_score(y_true=y_test, y_score=np.argmax(predicted_prob_rf,axis = 1))))\n",
        "print('Precision-Recall AUC: '+ str(sklearn.metrics.average_precision_score(y_true=y_test, y_score=np.argmax(predicted_prob_rf,axis = 1))))\n",
        "print('MCC: '+ str(sklearn.metrics.matthews_corrcoef(y_true=y_test, y_pred=predicted_rf)))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST\n",
            "[[23  3]\n",
            " [ 2 28]]\n",
            "\n",
            "TP: 28\n",
            "FP: 3\n",
            "TN: 23\n",
            "FN: 2\n",
            "\n",
            "Accuracy: 0.9107142857142857\n",
            "Precision: 0.9032258064516129\n",
            "Recall: 0.9333333333333333\n",
            "F-measure: 0.9180327868852459\n",
            "False Positive Rate:0.11538461538461539\n",
            "AUC: 0.908974358974359\n",
            "Precision-Recall AUC: 0.8787250384024577\n",
            "MCC: 0.8205830201566422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ld9Mkr-F5O8",
        "colab_type": "text"
      },
      "source": [
        "#Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRWlb3xXZfYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bn_relu(layer, dropout=0, **params):\n",
        "    layer = tf.keras.layers.BatchNormalization()(layer)\n",
        "    layer = tf.keras.layers.Activation(params['conv_activation'])(layer)\n",
        "\n",
        "    if dropout > 0:\n",
        "        layer = tf.keras.layers.Dropout(dropout)(layer)\n",
        "    return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQMTOgndZhdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_block(layer, filters, kernels, dropout, activation,\n",
        "                 cross_block=False, is_first=False, is_last=False, shrink=False):\n",
        "  # -BN-Act-Conv-BN-Act-Conv--\n",
        "  # ↳-----------------------↑\n",
        "  strides = 1\n",
        "  if shrink:\n",
        "    strides = 2\n",
        "  if cross_block:\n",
        "    shortcut = tf.keras.layers.Conv1D(filters=filters,\n",
        "                      kernel_size=strides,\n",
        "                      kernel_initializer='random_uniform',\n",
        "                      # kernel_regularizer=regularizers.l2(0.01),\n",
        "                      strides=strides,\n",
        "                      padding='same')(layer)\n",
        "  else:\n",
        "    shortcut = layer\n",
        "\n",
        "  if not is_first:\n",
        "    layer = bn_relu(layer, dropout=dropout, conv_activation=activation)\n",
        "\n",
        "  layer = tf.keras.layers.Conv1D(filters=filters,\n",
        "                 kernel_size=kernels,\n",
        "                 kernel_initializer='random_uniform',\n",
        "                 # kernel_regularizer=regularizers.l2(0.01),\n",
        "                 strides=strides,\n",
        "                 padding='same')(layer)\n",
        "  layer = bn_relu(layer, dropout=dropout, conv_activation=activation)\n",
        "  layer = tf.keras.layers.Conv1D(filters=filters,\n",
        "                 kernel_size=kernels,\n",
        "                 kernel_initializer='random_uniform',\n",
        "                 # kernel_regularizer=regularizers.l2(0.01),\n",
        "                 strides=1,\n",
        "                 padding='same')(layer)\n",
        "  layer = tf.keras.layers.add([shortcut, layer])\n",
        "\n",
        "  if is_last:\n",
        "    layer = bn_relu(layer, dropout=dropout, conv_activation=activation)\n",
        "\n",
        "  return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNk-GuzUYml7",
        "colab_type": "code",
        "outputId": "ddac8df7-1b76-47ba-d9a6-88f20127d616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "'''create model'''\n",
        "\n",
        "OUTPUT_SHAPE = 2\n",
        "input = tf.keras.layers.Input(shape=(1,SEQUENCE_LENGTH))\n",
        "\n",
        "layer = tf.keras.layers.Conv1D(filters=32,\n",
        "               kernel_size=3,\n",
        "               kernel_initializer='random_uniform',\n",
        "               # kernel_regularizer=regularizers.l2(0.01),\n",
        "               strides=1,\n",
        "               padding='same')(input)\n",
        "\n",
        "\n",
        "layer = resnet_block(layer=layer, filters=32, kernels=3, dropout=0, activation='relu')\n",
        "\n",
        "layer = resnet_block(layer, 64, 3, 0, 'relu', cross_block=True, shrink=True)\n",
        "layer = resnet_block(layer, 64, 3, 0, 'relu')\n",
        "\n",
        "layer = resnet_block(layer, 128, 3, 0, 'relu', cross_block=True, shrink=True)\n",
        "layer = resnet_block(layer, 128, 3, 0, 'relu')\n",
        "\n",
        "layer = resnet_block(layer, 256, 3, 0, 'relu', cross_block=True, shrink=True)\n",
        "layer = resnet_block(layer, 256, 3, 0, 'relu')\n",
        "layer = tf.keras.layers.Flatten()(layer)\n",
        "output = tf.keras.layers.Dense(units=OUTPUT_SHAPE, activation='softmax')(layer)\n",
        "\n",
        "model = tf.keras.Model(inputs=[input], outputs=[output])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.005)\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "monitor = tf.keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=1e-3, patience=25, mode='auto', restore_best_weights=True)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 1, 500)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_18 (Conv1D)              (None, 1, 32)        48032       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 1, 32)        128         conv1d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 1, 32)        0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_19 (Conv1D)              (None, 1, 32)        3104        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 1, 32)        128         conv1d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 1, 32)        0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_20 (Conv1D)              (None, 1, 32)        3104        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 1, 32)        0           conv1d_18[0][0]                  \n",
            "                                                                 conv1d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 1, 32)        128         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 1, 32)        0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_22 (Conv1D)              (None, 1, 64)        6208        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 1, 64)        256         conv1d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 1, 64)        0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_21 (Conv1D)              (None, 1, 64)        4160        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_23 (Conv1D)              (None, 1, 64)        12352       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 1, 64)        0           conv1d_21[0][0]                  \n",
            "                                                                 conv1d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 1, 64)        256         add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 1, 64)        0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_24 (Conv1D)              (None, 1, 64)        12352       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 1, 64)        256         conv1d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 1, 64)        0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_25 (Conv1D)              (None, 1, 64)        12352       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 1, 64)        0           add_8[0][0]                      \n",
            "                                                                 conv1d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 1, 64)        256         add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 1, 64)        0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 1, 128)       24704       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 1, 128)       512         conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 1, 128)       0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_26 (Conv1D)              (None, 1, 128)       16512       add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 1, 128)       49280       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 1, 128)       0           conv1d_26[0][0]                  \n",
            "                                                                 conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 1, 128)       512         add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 1, 128)       0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 1, 128)       49280       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 1, 128)       512         conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 1, 128)       0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_30 (Conv1D)              (None, 1, 128)       49280       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 1, 128)       0           add_10[0][0]                     \n",
            "                                                                 conv1d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 1, 128)       512         add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 1, 128)       0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_32 (Conv1D)              (None, 1, 256)       98560       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 1, 256)       1024        conv1d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 1, 256)       0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_31 (Conv1D)              (None, 1, 256)       65792       add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_33 (Conv1D)              (None, 1, 256)       196864      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 1, 256)       0           conv1d_31[0][0]                  \n",
            "                                                                 conv1d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 1, 256)       1024        add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 1, 256)       0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_34 (Conv1D)              (None, 1, 256)       196864      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 1, 256)       1024        conv1d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 1, 256)       0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_35 (Conv1D)              (None, 1, 256)       196864      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 1, 256)       0           add_12[0][0]                     \n",
            "                                                                 conv1d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 256)          0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            514         flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,052,706\n",
            "Trainable params: 1,049,442\n",
            "Non-trainable params: 3,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0IaTwTrOuJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 150\n",
        "EPOCHS = 100\n",
        "VALIDATION_SPLIT = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fXy69JAxT7O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "0f693452-26fa-4c84-cc7e-8b0f2aa8023c"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "261    0\n",
              "124    1\n",
              "33     0\n",
              "86     0\n",
              "265    0\n",
              "      ..\n",
              "188    0\n",
              "71     1\n",
              "106    1\n",
              "270    1\n",
              "102    1\n",
              "Name: is_vulnerable, Length: 223, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdK_0URfOw5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_reshaped = np.array(x_train).reshape(-1, 1, SEQUENCE_LENGTH) \n",
        "y_train_reshaped = np.eye(2)[y_train]\n",
        "\n",
        "x_test_reshaped =  np.array(x_test).reshape(-1, 1, SEQUENCE_LENGTH) \n",
        "y_test_reshaped = np.eye(2)[y_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZxFe7RJsVwm",
        "colab_type": "code",
        "outputId": "ddbe5292-3fb6-4b28-bea0-45bbe9ec9870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train_reshaped,\n",
        "          y_train_reshaped,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          validation_split=VALIDATION_SPLIT,\n",
        "          callbacks=[monitor])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200 samples, validate on 23 samples\n",
            "Epoch 1/100\n",
            "200/200 [==============================] - 2s 12ms/sample - loss: 2.2944 - acc: 0.5950 - val_loss: 0.6513 - val_acc: 0.7391\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.7430 - acc: 0.6150 - val_loss: 0.7290 - val_acc: 0.3478\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.8676 - acc: 0.5950 - val_loss: 0.5796 - val_acc: 0.7391\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.5754 - acc: 0.5950 - val_loss: 0.5318 - val_acc: 0.7391\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.5288 - acc: 0.6500 - val_loss: 0.5622 - val_acc: 0.7391\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.3851 - acc: 0.8350 - val_loss: 0.6011 - val_acc: 0.7826\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.4074 - acc: 0.8400 - val_loss: 0.6087 - val_acc: 0.6522\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.3225 - acc: 0.8450 - val_loss: 0.5963 - val_acc: 0.8696\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.3075 - acc: 0.8500 - val_loss: 0.5802 - val_acc: 0.7391\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.2520 - acc: 0.9000 - val_loss: 0.5699 - val_acc: 0.7391\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.2079 - acc: 0.9150 - val_loss: 0.5617 - val_acc: 0.8696\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.2112 - acc: 0.9100 - val_loss: 0.5590 - val_acc: 0.8696\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1790 - acc: 0.9200 - val_loss: 0.5610 - val_acc: 0.8696\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1928 - acc: 0.9200 - val_loss: 0.5693 - val_acc: 0.6957\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1570 - acc: 0.9150 - val_loss: 0.5785 - val_acc: 0.5652\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.2149 - acc: 0.8900 - val_loss: 0.5703 - val_acc: 0.5652\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.2278 - acc: 0.9050 - val_loss: 0.5582 - val_acc: 0.6087\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1653 - acc: 0.9250 - val_loss: 0.5523 - val_acc: 0.6087\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1986 - acc: 0.9050 - val_loss: 0.5571 - val_acc: 0.6087\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1624 - acc: 0.9300 - val_loss: 0.5580 - val_acc: 0.6087\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1492 - acc: 0.9200 - val_loss: 0.5448 - val_acc: 0.7391\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1378 - acc: 0.9350 - val_loss: 0.5096 - val_acc: 0.8696\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1766 - acc: 0.9200 - val_loss: 0.4836 - val_acc: 0.8696\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1501 - acc: 0.9350 - val_loss: 0.4838 - val_acc: 0.8696\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1856 - acc: 0.9400 - val_loss: 0.4892 - val_acc: 0.8696\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1235 - acc: 0.9500 - val_loss: 0.4943 - val_acc: 0.7391\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1045 - acc: 0.9600 - val_loss: 0.4904 - val_acc: 0.7391\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1033 - acc: 0.9600 - val_loss: 0.4809 - val_acc: 0.7391\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0807 - acc: 0.9650 - val_loss: 0.4753 - val_acc: 0.9130\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0917 - acc: 0.9650 - val_loss: 0.4810 - val_acc: 0.8696\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0794 - acc: 0.9700 - val_loss: 0.4785 - val_acc: 0.8696\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0793 - acc: 0.9550 - val_loss: 0.4515 - val_acc: 0.8696\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0964 - acc: 0.9550 - val_loss: 0.4308 - val_acc: 0.8696\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0924 - acc: 0.9750 - val_loss: 0.4314 - val_acc: 0.8261\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0789 - acc: 0.9600 - val_loss: 0.4485 - val_acc: 0.8696\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1407 - acc: 0.9450 - val_loss: 0.4407 - val_acc: 0.8261\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0893 - acc: 0.9650 - val_loss: 0.4283 - val_acc: 0.7391\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0988 - acc: 0.9500 - val_loss: 0.4392 - val_acc: 0.7391\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.1418 - acc: 0.9250 - val_loss: 0.4350 - val_acc: 0.7391\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0921 - acc: 0.9650 - val_loss: 0.4262 - val_acc: 0.7391\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0774 - acc: 0.9600 - val_loss: 0.4216 - val_acc: 0.9130\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0867 - acc: 0.9550 - val_loss: 0.4169 - val_acc: 0.8696\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0763 - acc: 0.9650 - val_loss: 0.4088 - val_acc: 0.9130\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0487 - acc: 0.9800 - val_loss: 0.4028 - val_acc: 0.8696\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0524 - acc: 0.9700 - val_loss: 0.3965 - val_acc: 0.7391\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0580 - acc: 0.9750 - val_loss: 0.3880 - val_acc: 0.7391\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0671 - acc: 0.9700 - val_loss: 0.3731 - val_acc: 0.7391\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0845 - acc: 0.9600 - val_loss: 0.3739 - val_acc: 0.7826\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0561 - acc: 0.9700 - val_loss: 0.3814 - val_acc: 0.9130\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0569 - acc: 0.9700 - val_loss: 0.3882 - val_acc: 0.8696\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0670 - acc: 0.9700 - val_loss: 0.3854 - val_acc: 0.9130\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0556 - acc: 0.9700 - val_loss: 0.3688 - val_acc: 0.9130\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 0s 2ms/sample - loss: 0.0545 - acc: 0.9700 - val_loss: 0.3565 - val_acc: 0.9130\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 1s 4ms/sample - loss: 0.0526 - acc: 0.9850 - val_loss: 0.3733 - val_acc: 0.7391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f91a26a3da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxE__Fxodh_R",
        "colab_type": "code",
        "outputId": "886155f4-f441-4e39-d71e-6c317081fa6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "print(\"TRAIN\")\n",
        "\n",
        "results = model.evaluate(x_train_reshaped, y_train_reshaped, batch_size=BATCH_SIZE)\n",
        "\n",
        "for num in range(0,len(model.metrics_names)):\n",
        "    print(model.metrics_names[num]+': '+str(results[num]))\n",
        "\n",
        "predicted_prob = model.predict(x_train_reshaped)\n",
        "predicted = np.argmax(predicted_prob,axis = 1)\n",
        "\n",
        "confusion = sklearn.metrics.confusion_matrix(y_true=y_train, y_pred=predicted)\n",
        "print(confusion)\n",
        "tn, fp, fn, tp = confusion.ravel()\n",
        "print('\\nTP:',tp)\n",
        "print('FP:',fp)\n",
        "print('TN:',tn)\n",
        "print('FN:',fn)\n",
        "\n",
        "## Performance measure\n",
        "print('\\nAccuracy: '+ str(sklearn.metrics.accuracy_score(y_true=y_train, y_pred=predicted)))\n",
        "print('Precision: '+ str(sklearn.metrics.precision_score(y_true=y_train, y_pred=predicted)))\n",
        "print('Recall: '+ str(sklearn.metrics.recall_score(y_true=y_train, y_pred=predicted)))\n",
        "print('F-measure: '+ str(sklearn.metrics.f1_score(y_true=y_train, y_pred=predicted)))\n",
        "print(\"False Positive Rate:\" + str(fp/(tn+fp)))\n",
        "print('AUC: '+ str(sklearn.metrics.roc_auc_score(y_true=y_train, y_score=np.argmax(predicted_prob,axis = 1))))\n",
        "print('Precision-Recall AUC: '+ str(sklearn.metrics.average_precision_score(y_true=y_train, y_score=np.argmax(predicted_prob,axis = 1))))\n",
        "print('MCC: '+ str(sklearn.metrics.matthews_corrcoef(y_true=y_train, y_pred=predicted)))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN\n",
            "223/223 [==============================] - 0s 161us/sample - loss: 0.4839 - acc: 0.8520\n",
            "loss: 0.48385296568207675\n",
            "acc: 0.85201794\n",
            "[[ 60  27]\n",
            " [  6 130]]\n",
            "\n",
            "TP: 130\n",
            "FP: 27\n",
            "TN: 60\n",
            "FN: 6\n",
            "\n",
            "Accuracy: 0.852017937219731\n",
            "Precision: 0.8280254777070064\n",
            "Recall: 0.9558823529411765\n",
            "F-measure: 0.8873720136518771\n",
            "False Positive Rate:0.3103448275862069\n",
            "AUC: 0.8227687626774849\n",
            "Precision-Recall AUC: 0.8184007715222275\n",
            "MCC: 0.689808878046755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glvnp1UMDwzn",
        "colab_type": "code",
        "outputId": "1b9e5256-16e1-4aa6-aab2-dab922ba5471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "print(\"TEST\")\n",
        "\n",
        "results = model.evaluate(x_test_reshaped, y_test_reshaped, batch_size=BATCH_SIZE)\n",
        "\n",
        "for num in range(0,len(model.metrics_names)):\n",
        "    print(model.metrics_names[num]+': '+str(results[num]))\n",
        "\n",
        "predicted_prob = model.predict(x_test_reshaped)\n",
        "predicted = np.argmax(predicted_prob,axis = 1)\n",
        "\n",
        "# predicted = model.predict_classes(x_test_reshaped)\n",
        "# predicted_prob = model.predict(x_test_reshaped)\n",
        "\n",
        "confusion = sklearn.metrics.confusion_matrix(y_true=y_test, y_pred=predicted)\n",
        "print(confusion)\n",
        "tn, fp, fn, tp = confusion.ravel()\n",
        "print('\\nTP:',tp)\n",
        "print('FP:',fp)\n",
        "print('TN:',tn)\n",
        "print('FN:',fn)\n",
        "\n",
        "## Performance measure\n",
        "print('\\nAccuracy: '+ str(sklearn.metrics.accuracy_score(y_true=y_test, y_pred=predicted)))\n",
        "print('Precision: '+ str(sklearn.metrics.precision_score(y_true=y_test, y_pred=predicted)))\n",
        "print('Recall: '+ str(sklearn.metrics.recall_score(y_true=y_test, y_pred=predicted)))\n",
        "print('F-measure: '+ str(sklearn.metrics.f1_score(y_true=y_test, y_pred=predicted)))\n",
        "print(\"False Positive Rate:\" + str(fp/(tn+fp)))\n",
        "print('AUC: '+ str(sklearn.metrics.roc_auc_score(y_true=y_test, y_score=np.argmax(predicted_prob,axis = 1))))\n",
        "print('Precision-Recall AUC: '+ str(sklearn.metrics.average_precision_score(y_true=y_test, y_score=np.argmax(predicted_prob,axis = 1))))\n",
        "print('MCC: '+ str(sklearn.metrics.matthews_corrcoef(y_true=y_test, y_pred=predicted)))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST\n",
            "\r56/56 [==============================] - 0s 185us/sample - loss: 0.5350 - acc: 0.8036\n",
            "loss: 0.535033106803894\n",
            "acc: 0.8035714\n",
            "[[16 10]\n",
            " [ 1 29]]\n",
            "\n",
            "TP: 29\n",
            "FP: 10\n",
            "TN: 16\n",
            "FN: 1\n",
            "\n",
            "Accuracy: 0.8035714285714286\n",
            "Precision: 0.7435897435897436\n",
            "Recall: 0.9666666666666667\n",
            "F-measure: 0.8405797101449275\n",
            "False Positive Rate:0.38461538461538464\n",
            "AUC: 0.7910256410256411\n",
            "Precision-Recall AUC: 0.7366605616605617\n",
            "MCC: 0.631323255446602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWpARYh0F60E",
        "colab_type": "text"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UAOBcVSeJfv",
        "colab_type": "code",
        "outputId": "38f74b71-58b6-4e5a-98de-8b4946343ef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# SVM\n",
        "print(\"SVM (kernel = linear)\")\n",
        "support_vector_classifier = SVC(kernel='linear', probability=True)\n",
        "support_vector_classifier.fit(x_train, y_train)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM (kernel = linear)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
              "    verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm8rVKZWeLH0",
        "colab_type": "code",
        "outputId": "5fdeb351-816e-4b74-f440-2a5654a1c8db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "print(\"TRAIN\")\n",
        "predicted_svm = support_vector_classifier.predict(x_train)\n",
        "predicted_prob_svm = support_vector_classifier.predict_proba(x_train)\n",
        "\n",
        "confusion = sklearn.metrics.confusion_matrix(y_true=y_train, y_pred=predicted_svm)\n",
        "print(confusion)\n",
        "tn, fp, fn, tp = confusion.ravel()\n",
        "print('\\nTP:',tp)\n",
        "print('FP:',fp)\n",
        "print('TN:',tn)\n",
        "print('FN:',fn)\n",
        "\n",
        "## Performance measure\n",
        "print('\\nAccuracy: '+ str(sklearn.metrics.accuracy_score(y_true=y_train, y_pred=predicted_svm)))\n",
        "print('Precision: '+ str(sklearn.metrics.precision_score(y_true=y_train, y_pred=predicted_svm)))\n",
        "print('Recall: '+ str(sklearn.metrics.recall_score(y_true=y_train, y_pred=predicted_svm)))\n",
        "print('F-measure: '+ str(sklearn.metrics.f1_score(y_true=y_train, y_pred=predicted_svm)))\n",
        "print(\"False Positive Rate:\" + str(fp/(tn+fp)))\n",
        "print('AUC: '+ str(sklearn.metrics.roc_auc_score(y_true=y_train, y_score=np.argmax(predicted_prob_svm,axis = 1))))\n",
        "print('Precision-Recall AUC: '+ str(sklearn.metrics.average_precision_score(y_true=y_train, y_score=np.argmax(predicted_prob_svm,axis = 1))))\n",
        "print('MCC: '+ str(sklearn.metrics.matthews_corrcoef(y_true=y_train, y_pred=predicted_svm)))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN\n",
            "[[ 85   2]\n",
            " [ 12 124]]\n",
            "\n",
            "TP: 124\n",
            "FP: 2\n",
            "TN: 85\n",
            "FN: 12\n",
            "\n",
            "Accuracy: 0.9372197309417041\n",
            "Precision: 0.9841269841269841\n",
            "Recall: 0.9117647058823529\n",
            "F-measure: 0.9465648854961831\n",
            "False Positive Rate:0.022988505747126436\n",
            "AUC: 0.9423174442190668\n",
            "Precision-Recall AUC: 0.9469031814659721\n",
            "MCC: 0.8744809583637778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as4GgGU_pRoN",
        "colab_type": "code",
        "outputId": "80fe5692-7e94-49df-f9cc-f906cc438ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "print(\"TEST\")\n",
        "\n",
        "predicted_svm = support_vector_classifier.predict(x_test)\n",
        "predicted_prob_svm = support_vector_classifier.predict_proba(x_test)\n",
        "\n",
        "confusion = sklearn.metrics.confusion_matrix(y_true=y_test, y_pred=predicted_svm)\n",
        "print(confusion)\n",
        "tn, fp, fn, tp = confusion.ravel()\n",
        "print('\\nTP:',tp)\n",
        "print('FP:',fp)\n",
        "print('TN:',tn)\n",
        "print('FN:',fn)\n",
        "\n",
        "## Performance measure\n",
        "print('\\nAccuracy: '+ str(sklearn.metrics.accuracy_score(y_true=y_test, y_pred=predicted_svm)))\n",
        "print('Precision: '+ str(sklearn.metrics.precision_score(y_true=y_test, y_pred=predicted_svm)))\n",
        "print('Recall: '+ str(sklearn.metrics.recall_score(y_true=y_test, y_pred=predicted_svm)))\n",
        "print('F-measure: '+ str(sklearn.metrics.f1_score(y_true=y_test, y_pred=predicted_svm)))\n",
        "print(\"False Positive Rate:\" + str(fp/(tn+fp)))\n",
        "print('AUC: '+ str(sklearn.metrics.roc_auc_score(y_true=y_test, y_score=np.argmax(predicted_prob_svm,axis = 1))))\n",
        "print('Precision-Recall AUC: '+ str(sklearn.metrics.average_precision_score(y_true=y_test, y_score=np.argmax(predicted_prob_svm,axis = 1))))\n",
        "print('MCC: '+ str(sklearn.metrics.matthews_corrcoef(y_true=y_test, y_pred=predicted_svm)))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST\n",
            "[[24  2]\n",
            " [ 7 23]]\n",
            "\n",
            "TP: 23\n",
            "FP: 2\n",
            "TN: 24\n",
            "FN: 7\n",
            "\n",
            "Accuracy: 0.8392857142857143\n",
            "Precision: 0.92\n",
            "Recall: 0.7666666666666667\n",
            "F-measure: 0.8363636363636363\n",
            "False Positive Rate:0.07692307692307693\n",
            "AUC: 0.8615384615384616\n",
            "Precision-Recall AUC: 0.8456043956043956\n",
            "MCC: 0.691964991918924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hobCjX93oBox",
        "colab_type": "code",
        "outputId": "6803c2aa-485c-4c98-a7b2-970c145c5133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "fpr_svm, tpr_svm, _ = sklearn.metrics.roc_curve(y_test, predicted_prob_svm[:, 1])\n",
        "roc_auc_svm = sklearn.metrics.auc(fpr_svm, tpr_svm)\n",
        "\n",
        "fpr_rf, tpr_rf, _ = sklearn.metrics.roc_curve(y_test, predicted_prob_rf[:, 1])\n",
        "roc_auc_rf = sklearn.metrics.auc(fpr_rf, tpr_rf)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr_svm, tpr_svm, color='darkorange',\n",
        "         lw=2, label='Randomforest (area = %0.2f)' % roc_auc_svm)\n",
        "plt.plot(fpr_rf, tpr_rf, color='darkgreen',\n",
        "         lw=2, label='svm(area = %0.2f)' % roc_auc_rf)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/5sQ53gKG4bEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw2IoruPj6Tz",
        "colab_type": "text"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzEcOih6OVk3",
        "colab_type": "code",
        "outputId": "d8cf36d6-9dbc-427c-dad1-d48d1a08901a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "# Random Forest\n",
        "print(\"RANDOM FOREST\")\n",
        "print('\\nAccuracy: '+ str(sklearn.metrics.accuracy_score(y_true=y_test, y_pred=predicted_rf)))\n",
        "print('Precision: '+ str(sklearn.metrics.precision_score(y_true=y_test, y_pred=predicted_rf)))\n",
        "print('Recall: '+ str(sklearn.metrics.recall_score(y_true=y_test, y_pred=predicted_rf)))\n",
        "print('F-measure: '+ str(sklearn.metrics.f1_score(y_true=y_test, y_pred=predicted_rf)))\n",
        "confusion = sklearn.metrics.confusion_matrix(y_true=y_test, y_pred=predicted_rf)\n",
        "tn, fp, fn, tp = confusion.ravel()\n",
        "print(\"False Positive Rate:\" + str(fp/(tn+fp)))\n",
        "print('AUC: '+ str(sklearn.metrics.roc_auc_score(y_true=y_test, y_score=np.argmax(predicted_prob_rf,axis = 1))))\n",
        "print('Precision-Recall AUC: '+ str(sklearn.metrics.average_precision_score(y_true=y_test, y_score=np.argmax(predicted_prob_rf,axis = 1))))\n",
        "print('MCC: '+ str(sklearn.metrics.matthews_corrcoef(y_true=y_test, y_pred=predicted_rf)))\n",
        "print(\"\\n\")\n",
        "\n",
        "## SVM\n",
        "print(\"SVM\")\n",
        "print('\\nAccuracy: '+ str(sklearn.metrics.accuracy_score(y_true=y_test, y_pred=predicted_svm)))\n",
        "print('Precision: '+ str(sklearn.metrics.precision_score(y_true=y_test, y_pred=predicted_svm)))\n",
        "print('Recall: '+ str(sklearn.metrics.recall_score(y_true=y_test, y_pred=predicted_svm)))\n",
        "print('F-measure: '+ str(sklearn.metrics.f1_score(y_true=y_test, y_pred=predicted_svm)))\n",
        "confusion = sklearn.metrics.confusion_matrix(y_true=y_test, y_pred=predicted_svm)\n",
        "tn, fp, fn, tp = confusion.ravel()\n",
        "print(\"False Positive Rate:\" + str(fp/(tn+fp)))\n",
        "print('AUC: '+ str(sklearn.metrics.roc_auc_score(y_true=y_test, y_score=np.argmax(predicted_prob_svm,axis = 1))))\n",
        "print('Precision-Recall AUC: '+ str(sklearn.metrics.average_precision_score(y_true=y_test, y_score=np.argmax(predicted_prob_svm,axis = 1))))\n",
        "print('MCC: '+ str(sklearn.metrics.matthews_corrcoef(y_true=y_test, y_pred=predicted_svm)))\n",
        "print(\"\\n\")\n",
        "\n",
        "#Resnet\n",
        "print(\"RESNET\")\n",
        "print('\\nAccuracy: '+ str(sklearn.metrics.accuracy_score(y_true=y_test, y_pred=predicted)))\n",
        "print('Precision: '+ str(sklearn.metrics.precision_score(y_true=y_test, y_pred=predicted)))\n",
        "print('Recall: '+ str(sklearn.metrics.recall_score(y_true=y_test, y_pred=predicted)))\n",
        "print('F-measure: '+ str(sklearn.metrics.f1_score(y_true=y_test, y_pred=predicted)))\n",
        "confusion = sklearn.metrics.confusion_matrix(y_true=y_test, y_pred=predicted)\n",
        "tn, fp, fn, tp = confusion.ravel()\n",
        "print(\"False Positive Rate:\" + str(fp/(tn+fp)))\n",
        "print('AUC: '+ str(sklearn.metrics.roc_auc_score(y_true=y_test, y_score=np.argmax(predicted_prob,axis = 1))))\n",
        "print('Precision-Recall AUC: '+ str(sklearn.metrics.average_precision_score(y_true=y_test, y_score=np.argmax(predicted_prob,axis = 1))))\n",
        "print('MCC: '+ str(sklearn.metrics.matthews_corrcoef(y_true=y_test, y_pred=predicted)))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RANDOM FOREST\n",
            "\n",
            "Accuracy: 0.9107142857142857\n",
            "Precision: 0.9032258064516129\n",
            "Recall: 0.9333333333333333\n",
            "F-measure: 0.9180327868852459\n",
            "False Positive Rate:0.11538461538461539\n",
            "AUC: 0.908974358974359\n",
            "Precision-Recall AUC: 0.8787250384024577\n",
            "MCC: 0.8205830201566422\n",
            "\n",
            "\n",
            "SVM\n",
            "\n",
            "Accuracy: 0.8392857142857143\n",
            "Precision: 0.92\n",
            "Recall: 0.7666666666666667\n",
            "F-measure: 0.8363636363636363\n",
            "False Positive Rate:0.07692307692307693\n",
            "AUC: 0.8615384615384616\n",
            "Precision-Recall AUC: 0.8456043956043956\n",
            "MCC: 0.691964991918924\n",
            "\n",
            "\n",
            "RESNET\n",
            "\n",
            "Accuracy: 0.8035714285714286\n",
            "Precision: 0.7435897435897436\n",
            "Recall: 0.9666666666666667\n",
            "F-measure: 0.8405797101449275\n",
            "False Positive Rate:0.38461538461538464\n",
            "AUC: 0.7910256410256411\n",
            "Precision-Recall AUC: 0.7366605616605617\n",
            "MCC: 0.631323255446602\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}